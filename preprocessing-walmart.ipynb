{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18599,"databundleVersionId":1236839,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-06T01:29:04.856443Z","iopub.execute_input":"2023-12-06T01:29:04.856829Z","iopub.status.idle":"2023-12-06T01:29:05.256355Z","shell.execute_reply.started":"2023-12-06T01:29:04.856795Z","shell.execute_reply":"2023-12-06T01:29:05.255418Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\ntrain_data = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\nsell_prices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:30:53.690383Z","iopub.execute_input":"2023-12-06T01:30:53.690932Z","iopub.status.idle":"2023-12-06T01:31:05.614230Z","shell.execute_reply.started":"2023-12-06T01:30:53.690898Z","shell.execute_reply":"2023-12-06T01:31:05.613361Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"for d in range(1942,1970):\n    col = 'd_' + str(d)\n    train_data[col] = 0\n    train_data[col] = train_data[col].astype(np.int16)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:31:45.789370Z","iopub.execute_input":"2023-12-06T01:31:45.789809Z","iopub.status.idle":"2023-12-06T01:31:45.821159Z","shell.execute_reply.started":"2023-12-06T01:31:45.789772Z","shell.execute_reply":"2023-12-06T01:31:45.820040Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:33:03.272363Z","iopub.execute_input":"2023-12-06T01:33:03.272765Z","iopub.status.idle":"2023-12-06T01:33:03.287077Z","shell.execute_reply.started":"2023-12-06T01:33:03.272724Z","shell.execute_reply":"2023-12-06T01:33:03.285457Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data = downcast(train_data)\nsell_prices = downcast(sell_prices)\ncalendar = downcast(calendar)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:33:04.641145Z","iopub.execute_input":"2023-12-06T01:33:04.642108Z","iopub.status.idle":"2023-12-06T01:33:07.197463Z","shell.execute_reply.started":"2023-12-06T01:33:04.642063Z","shell.execute_reply":"2023-12-06T01:33:07.196277Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = pd.melt(frame=train_data, \n             id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n             var_name=\"d\", value_name=\"sold\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:33:28.573574Z","iopub.execute_input":"2023-12-06T01:33:28.574633Z","iopub.status.idle":"2023-12-06T01:33:38.446364Z","shell.execute_reply.started":"2023-12-06T01:33:28.574593Z","shell.execute_reply":"2023-12-06T01:33:38.445195Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(left=df, right=calendar, how=\"left\", on=\"d\")\ndf = pd.merge(left=df, right=sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:34:08.222891Z","iopub.execute_input":"2023-12-06T01:34:08.223288Z","iopub.status.idle":"2023-12-06T01:34:40.677747Z","shell.execute_reply.started":"2023-12-06T01:34:08.223254Z","shell.execute_reply":"2023-12-06T01:34:40.676546Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:34:58.517029Z","iopub.execute_input":"2023-12-06T01:34:58.517436Z","iopub.status.idle":"2023-12-06T01:34:58.552926Z","shell.execute_reply.started":"2023-12-06T01:34:58.517405Z","shell.execute_reply":"2023-12-06T01:34:58.551842Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id    d  sold       date  wm_yr_wk  ... month  year  event_name_1  \\\n0       CA  d_1     0 2011-01-29     11101  ...     1  2011           NaN   \n1       CA  d_1     0 2011-01-29     11101  ...     1  2011           NaN   \n2       CA  d_1     0 2011-01-29     11101  ...     1  2011           NaN   \n3       CA  d_1     0 2011-01-29     11101  ...     1  2011           NaN   \n4       CA  d_1     0 2011-01-29     11101  ...     1  2011           NaN   \n\n   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n0           NaN          NaN          NaN       0       0        0         NaN  \n1           NaN          NaN          NaN       0       0        0         NaN  \n2           NaN          NaN          NaN       0       0        0         NaN  \n3           NaN          NaN          NaN       0       0        0         NaN  \n4           NaN          NaN          NaN       0       0        0         NaN  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sold</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Implementing features\")\ndf[\"d\"] = df[\"d\"].apply(lambda x: int(x[2:])).astype(np.int16)\ndf[\"snap\"] = df[\"snap_CA\"] + df[\"snap_TX\"] + df[\"snap_WI\"]\ndf[\"snap\"] = df[\"snap\"].map(lambda x: 1 if x >= 1 else 0).astype(np.int8)\ndf[\"weekend\"] = df[\"wday\"].map(lambda x : 1 if x < 3 else 0).astype(np.int8)\ndf[\"sell_price\"] = df['sell_price'].fillna(df.groupby('id')['sell_price'].transform('median'))\n\ndf = df.drop([\"date\", \"weekday\", \"wm_yr_wk\", \"event_name_2\", \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:43:59.052059Z","iopub.execute_input":"2023-12-06T01:43:59.053456Z","iopub.status.idle":"2023-12-06T01:45:28.841870Z","shell.execute_reply.started":"2023-12-06T01:43:59.053412Z","shell.execute_reply":"2023-12-06T01:45:28.840693Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Implementing features\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:45:49.502035Z","iopub.execute_input":"2023-12-06T01:45:49.502419Z","iopub.status.idle":"2023-12-06T01:45:49.526178Z","shell.execute_reply.started":"2023-12-06T01:45:49.502389Z","shell.execute_reply":"2023-12-06T01:45:49.524600Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                              id        item_id    dept_id   cat_id store_id  \\\n0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n\n  state_id  d  sold  wday  month  year event_name_1 event_type_1  sell_price  \\\n0       CA  1     0     1      1  2011          NaN          NaN    8.257812   \n1       CA  1     0     1      1  2011          NaN          NaN    3.970703   \n2       CA  1     0     1      1  2011          NaN          NaN    2.970703   \n3       CA  1     0     1      1  2011          NaN          NaN    4.640625   \n4       CA  1     0     1      1  2011          NaN          NaN    2.980469   \n\n   snap  weekend  \n0     0        1  \n1     0        1  \n2     0        1  \n3     0        1  \n4     0        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sold</th>\n      <th>wday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>sell_price</th>\n      <th>snap</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>HOBBIES_1_001</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.257812</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>HOBBIES_1_002</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.970703</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>HOBBIES_1_003</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.970703</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>HOBBIES_1_004</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.640625</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>HOBBIES_1_005</td>\n      <td>HOBBIES_1</td>\n      <td>HOBBIES</td>\n      <td>CA_1</td>\n      <td>CA</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.980469</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Label Encoding as below\")\nd_id = dict(zip(df[\"id\"].cat.codes, df[\"id\"]))\nd_store = dict(zip(df[\"store_id\"].cat.codes, df[\"store_id\"]))\nd_dept = dict(zip(df[\"dept_id\"].cat.codes, df[\"dept_id\"]))\nd_cat = dict(zip(df[\"cat_id\"].cat.codes, df[\"cat_id\"]))\ndf[\"id\"] = df[\"id\"].cat.codes\ndf[\"item_id\"] = df[\"item_id\"].cat.codes\ndf[\"dept_id\"] = df[\"dept_id\"].cat.codes\ndf[\"cat_id\"] = df[\"cat_id\"].cat.codes\ndf[\"store_id\"] = df[\"store_id\"].cat.codes\ndf[\"state_id\"] = df[\"state_id\"].cat.codes\ndf[\"event_name_1\"] = df[\"event_name_1\"].cat.codes\ndf[\"event_type_1\"] = df[\"event_type_1\"].cat.codes","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:48:09.899168Z","iopub.execute_input":"2023-12-06T01:48:09.899615Z","iopub.status.idle":"2023-12-06T01:48:56.196545Z","shell.execute_reply.started":"2023-12-06T01:48:09.899581Z","shell.execute_reply":"2023-12-06T01:48:56.195186Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Label Encoding as below\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create total sale for each store\nsum_df = df.groupby([\"store_id\", \"d\"])[\"sold\"].sum().reset_index()\ndf = pd.merge(left=df, right=sum_df, how=\"left\", on=[\"d\", \"store_id\"])\ndf.rename(columns={'sold_x': 'sold','sold_y': 'total_sale_store'}, inplace=True)\n\n# Create total sale for each department\nsum_df_dept = df.groupby([\"dept_id\", \"d\"])[\"sold\"].sum().reset_index()\ndf = pd.merge(left=df, right=sum_df_dept, how=\"left\", on=[\"d\", \"dept_id\"])\ndf.rename(columns={'sold_x': 'sold','sold_y': 'total_sale_dept'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:49:57.594731Z","iopub.execute_input":"2023-12-06T01:49:57.595273Z","iopub.status.idle":"2023-12-06T01:50:18.506332Z","shell.execute_reply.started":"2023-12-06T01:49:57.595212Z","shell.execute_reply":"2023-12-06T01:50:18.505189Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(\"Calulating Lags for the days more than 28 as there could be null values in the features \\\nwhile predicting\")\n\nlags = [5,8,10,25,26,27,28,29,30,31,32,33,34,35,36,37,40,50,55,60,120]\nfor lag in lags:\n    df['sales_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:53:42.325292Z","iopub.execute_input":"2023-12-06T01:53:42.325666Z","iopub.status.idle":"2023-12-06T01:57:21.436318Z","shell.execute_reply.started":"2023-12-06T01:53:42.325639Z","shell.execute_reply":"2023-12-06T01:57:21.434696Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Calulating Lags for the days more than 28 as there could be null values in the features while predicting\nCPU times: user 2min 50s, sys: 47.9 s, total: 3min 38s\nWall time: 3min 39s\n","output_type":"stream"}]},{"cell_type":"code","source":"for d_shift in [1,7,14]: \n    print('Shifting period:', d_shift)\n    for d_window in [7,14,30,60]:\n        col_name = 'rolling_mean_tmp_'+str(d_shift)+'_'+str(d_window)\n        df[col_name] = df.groupby(['id'])['sold'].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:57:37.312841Z","iopub.execute_input":"2023-12-06T01:57:37.313287Z","iopub.status.idle":"2023-12-06T02:06:14.574972Z","shell.execute_reply.started":"2023-12-06T01:57:37.313243Z","shell.execute_reply":"2023-12-06T02:06:14.574049Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Shifting period: 1\nShifting period: 7\nShifting period: 14\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in [7,14,30,60,180]:\n    print('Rolling period:', i)\n    df['rolling_mean_'+str(i)] = df.groupby(['id'])['sold'].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n    df['rolling_std_'+str(i)]  = df.groupby(['id'])['sold'].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:06:43.681458Z","iopub.status.idle":"2023-12-06T02:06:43.683149Z","shell.execute_reply.started":"2023-12-06T02:06:43.682827Z","shell.execute_reply":"2023-12-06T02:06:43.682864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(\"Mean Encoding\")\ndf[\"state_mean\"] = df.groupby(\"state_id\")[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"store_mean\"] = df.groupby(\"store_id\")[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"cat_mean\"] = df.groupby(\"cat_id\")[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"dept_mean\"] = df.groupby(\"dept_id\")[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"state_cat_mean\"] = df.groupby([\"state_id\", \"cat_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"state_dept_mean\"] = df.groupby([\"state_id\", \"dept_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"store_cat_mean\"] = df.groupby([\"store_id\", \"cat_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"store_cat_mean\"] = df.groupby([\"dept_id\", \"cat_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"item_id_mean\"] = df.groupby(\"item_id\")[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"item_state_mean\"] = df.groupby([\"item_id\", \"state_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\ndf[\"item_store_mean\"] = df.groupby([\"item_id\", \"store_id\"])[\"sold\"].transform(\"mean\").astype(np.float16)\n\nprint(\"Median Encoding\")\ndf[\"state_median\"] = df.groupby(\"state_id\")[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"store_median\"] = df.groupby(\"store_id\")[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"cat_median\"] = df.groupby(\"cat_id\")[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"dept_median\"] = df.groupby(\"dept_id\")[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"state_cat_median\"] = df.groupby([\"state_id\", \"cat_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"state_dept_median\"] = df.groupby([\"state_id\", \"dept_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"store_cat_median\"] = df.groupby([\"store_id\", \"cat_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"store_cat_median\"] = df.groupby([\"dept_id\", \"cat_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"item_id_median\"] = df.groupby(\"item_id\")[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"item_state_median\"] = df.groupby([\"item_id\", \"state_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\ndf[\"item_store_median\"] = df.groupby([\"item_id\", \"store_id\"])[\"sold\"].transform(\"median\").astype(np.float16)\n\nprint(\"Standard Deviation encoding\")\ndf[\"state_std\"] = df.groupby(\"state_id\")[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"store_std\"] = df.groupby(\"store_id\")[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"cat_std\"] = df.groupby(\"cat_id\")[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"dept_std\"] = df.groupby(\"dept_id\")[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"state_cat_std\"] = df.groupby([\"state_id\", \"cat_id\"])[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"state_dept_std\"] = df.groupby([\"state_id\", \"dept_id\"])[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"store_cat_std\"] = df.groupby([\"store_id\", \"cat_id\"])[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"store_cat_std\"] = df.groupby([\"dept_id\", \"cat_id\"])[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"item_id_std\"] = df.groupby(\"item_id\")[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"item_state_std\"] = df.groupby([\"item_id\", \"state_id\"])[\"sold\"].transform(\"std\").astype(np.float16)\ndf[\"item_store_std\"] = df.groupby([\"item_id\", \"store_id\"])[\"sold\"].transform(\"std\").astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:50:46.038095Z","iopub.execute_input":"2023-12-06T01:50:46.038519Z","iopub.status.idle":"2023-12-06T01:52:49.164658Z","shell.execute_reply.started":"2023-12-06T01:50:46.038485Z","shell.execute_reply":"2023-12-06T01:52:49.163801Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Mean Encoding\nMedian Encoding\nStandard Deviation encoding\nCPU times: user 1min 34s, sys: 27.9 s, total: 2min 2s\nWall time: 2min 3s\n","output_type":"stream"}]},{"cell_type":"code","source":"df.to_pickle('data.pkl')\ndel df","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:06:14.576474Z","iopub.execute_input":"2023-12-06T02:06:14.577391Z","iopub.status.idle":"2023-12-06T02:06:43.679628Z","shell.execute_reply.started":"2023-12-06T02:06:14.577357Z","shell.execute_reply":"2023-12-06T02:06:43.677666Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n","\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"],"ename":"NameError","evalue":"name 'gc' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:07:08.464904Z","iopub.execute_input":"2023-12-06T02:07:08.465472Z","iopub.status.idle":"2023-12-06T02:07:09.005741Z","shell.execute_reply.started":"2023-12-06T02:07:08.465427Z","shell.execute_reply":"2023-12-06T02:07:09.004438Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"1095"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}